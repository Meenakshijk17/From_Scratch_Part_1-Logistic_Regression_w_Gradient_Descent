# From Scratch - Part-2: Logistic Regression using Gradient Descent

### Aim
This project aims to develop and implement logistic regression algorithm with gradient descent from scratch, without using ML libraries like Scikit-Learn.


### Motivation - More than just a *model.fit()*
Diving into manual implementation of logistic regression with gradient descent is essential for mastering this fundamental machine learning technique. This hands-on approach unveils the intricacies of gradient descent optimization, enhancing comprehension of concepts like parameter adjustment and model convergence. Through customization and experimentation, practitioners gain practical insights into fine-tuning hyperparameters and addressing challenges like overfitting. Crafting the algorithm from scratch fosters a deeper understanding of its theoretical underpinnings, transcending reliance on pre-existing implementations. This exercise encourages critical thinking and empowers practitioners to tailor solutions to specific use cases, thus advancing proficiency in logistic regression and gradient descent optimization within the realm of data science.